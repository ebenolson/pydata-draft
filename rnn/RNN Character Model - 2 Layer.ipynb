{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 770 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "from collections import Counter\n",
    "from lasagne.utils import floatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = open('claims.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCABULARY = set(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(VOCABULARY)\n",
    "\n",
    "CHAR_TO_IX = {c: i for i, c in enumerate(VOCABULARY)}\n",
    "IX_TO_CHAR = {i: c for i, c in enumerate(VOCABULARY)}\n",
    "CHAR_TO_ONEHOT = {c: np.eye(VOCAB_SIZE)[i] for i, c in enumerate(VOCABULARY)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 50\n",
    "BATCH_SIZE = 50\n",
    "RNN_HIDDEN_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_corpus = corpus[:(len(corpus) * 9 // 10)]\n",
    "val_corpus = corpus[(len(corpus) * 9 // 10):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_batch_generator(corpus, size=BATCH_SIZE):\n",
    "    startidx = np.random.randint(0, len(corpus) - SEQUENCE_LENGTH - 1, size=size)\n",
    "\n",
    "    while True:\n",
    "        items = np.array([corpus[start:start + SEQUENCE_LENGTH + 1] for start in startidx])\n",
    "        startidx = (startidx + SEQUENCE_LENGTH) % (len(corpus) - SEQUENCE_LENGTH - 1)\n",
    "        yield items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prep_batch_for_network(batch):\n",
    "    x_seq = np.zeros((len(batch), SEQUENCE_LENGTH, VOCAB_SIZE), dtype='float32')\n",
    "    y_seq = np.zeros((len(batch), SEQUENCE_LENGTH), dtype='int32')\n",
    "\n",
    "    for i, item in enumerate(batch):\n",
    "        for j in range(SEQUENCE_LENGTH):\n",
    "            x_seq[i, j] = CHAR_TO_ONEHOT[item[j]]\n",
    "            y_seq[i, j] = CHAR_TO_IX[item[j + 1]]\n",
    "\n",
    "    return x_seq, y_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_sym = T.tensor3()\n",
    "y_sym = T.imatrix()\n",
    "hid_init_sym = T.matrix()\n",
    "hid2_init_sym = T.matrix()\n",
    "\n",
    "\n",
    "l_input = lasagne.layers.InputLayer((None, SEQUENCE_LENGTH, VOCAB_SIZE))\n",
    "\n",
    "l_rnn = lasagne.layers.GRULayer(l_input,\n",
    "                                  num_units=RNN_HIDDEN_SIZE,\n",
    "                                  grad_clipping=5.,\n",
    "                                  hid_init=hid_init_sym,\n",
    "                                  )\n",
    "\n",
    "l_rnn2 = lasagne.layers.GRULayer(l_rnn,\n",
    "                                  num_units=RNN_HIDDEN_SIZE,\n",
    "                                  grad_clipping=5.,\n",
    "                                  hid_init=hid2_init_sym,\n",
    "                                  )\n",
    "\n",
    "\n",
    "l_shp = lasagne.layers.ReshapeLayer(l_rnn2, (-1, RNN_HIDDEN_SIZE))\n",
    "\n",
    "l_decoder = lasagne.layers.DenseLayer(l_shp,\n",
    "                                      num_units=VOCAB_SIZE,\n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "l_out = lasagne.layers.ReshapeLayer(l_decoder, (-1, SEQUENCE_LENGTH, VOCAB_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hid_out, hid2_out, prob_out = lasagne.layers.get_output([l_rnn, l_rnn2, l_out],\n",
    "                                                        {l_input: x_sym})\n",
    "\n",
    "hid_out = hid_out[:, -1]\n",
    "hid2_out = hid2_out[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_cross_ent(net_output, targets):\n",
    "    preds = T.reshape(net_output, (-1, VOCAB_SIZE))\n",
    "    targets = T.flatten(targets)\n",
    "    cost = T.nnet.categorical_crossentropy(preds, targets)\n",
    "    return cost\n",
    "\n",
    "loss = T.mean(calc_cross_ent(prob_out, y_sym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_sh = theano.shared(floatX(0.002))\n",
    "\n",
    "MAX_GRAD_NORM = 15\n",
    "\n",
    "all_params = lasagne.layers.get_all_params(l_out, trainable=True)\n",
    "\n",
    "all_grads = T.grad(loss, all_params)\n",
    "all_grads = [T.clip(g, -5, 5) for g in all_grads]\n",
    "all_grads, norm = lasagne.updates.total_norm_constraint(\n",
    "    all_grads, MAX_GRAD_NORM, return_norm=True)\n",
    "\n",
    "updates = lasagne.updates.adam(all_grads, all_params, learning_rate=lr_sh)\n",
    "\n",
    "f_train = theano.function([x_sym, y_sym, hid_init_sym, hid2_init_sym],\n",
    "                          [loss, norm, hid_out, hid2_out],\n",
    "                          updates=updates\n",
    "                         )\n",
    "\n",
    "f_val = theano.function([x_sym, y_sym, hid_init_sym, hid2_init_sym], [loss, hid_out, hid2_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss_train: 4.55749225616, norm: 0.760300338268\n",
      "Iteration 250, loss_train: 1.66040706635, norm: 0.38279491663\n",
      "Iteration 500, loss_train: 1.29986417294, norm: 0.293704122305\n",
      "Iteration 750, loss_train: 1.25550210476, norm: 0.290590673685\n",
      "Iteration 1000, loss_train: 1.13784217834, norm: 0.32186254859\n",
      "Iteration 1250, loss_train: 1.19803094864, norm: 0.331361681223\n",
      "Iteration 1500, loss_train: 1.05421900749, norm: 0.293191343546\n",
      "Iteration 1750, loss_train: 1.02515113354, norm: 0.250425338745\n",
      "Iteration 2000, loss_train: 0.989981472492, norm: 0.254016608\n",
      "Iteration 2250, loss_train: 1.04801535606, norm: 0.27374368906\n",
      "Iteration 2500, loss_train: 1.11283314228, norm: 0.29329881072\n",
      "Iteration 2750, loss_train: 0.996952950954, norm: 0.26028880477\n",
      "Iteration 3000, loss_train: 1.01600551605, norm: 0.25490385294\n",
      "Iteration 3250, loss_train: 1.07221901417, norm: 0.287651866674\n",
      "Iteration 3500, loss_train: 1.02552270889, norm: 0.286253511906\n",
      "Iteration 3750, loss_train: 0.975072741508, norm: 0.26708522439\n",
      "Iteration 4000, loss_train: 0.977166295052, norm: 0.267534941435\n",
      "Iteration 4250, loss_train: 0.952759861946, norm: 0.247367411852\n",
      "Iteration 4500, loss_train: 1.09841072559, norm: 0.275455236435\n",
      "Iteration 4750, loss_train: 0.99228566885, norm: 0.261342525482\n",
      "Iteration 5000, loss_train: 1.00742459297, norm: 0.255170732737\n",
      "Iteration 5250, loss_train: 0.923252820969, norm: 0.255060046911\n",
      "Iteration 5500, loss_train: 0.995961308479, norm: 0.267254501581\n",
      "Iteration 5750, loss_train: 1.01092278957, norm: 0.253289073706\n",
      "Iteration 6000, loss_train: 1.05679404736, norm: 0.277374207973\n",
      "Iteration 6250, loss_train: 1.03392899036, norm: 0.280803531408\n",
      "Iteration 6500, loss_train: 0.982242584229, norm: 0.266266673803\n",
      "Iteration 6750, loss_train: 1.07301867008, norm: 0.284660041332\n",
      "Iteration 7000, loss_train: 1.00019931793, norm: 0.277452260256\n",
      "Iteration 7250, loss_train: 0.989062309265, norm: 0.276072889566\n",
      "Iteration 7500, loss_train: 0.962711513042, norm: 0.239038124681\n",
      "Iteration 7750, loss_train: 0.954353928566, norm: 0.241415902972\n",
      "Iteration 8000, loss_train: 0.945852220058, norm: 0.249413609505\n",
      "Iteration 8250, loss_train: 0.907465517521, norm: 0.240373641253\n",
      "Iteration 8500, loss_train: 0.95824277401, norm: 0.240569263697\n",
      "Iteration 8750, loss_train: 0.926833093166, norm: 0.248387336731\n",
      "Iteration 9000, loss_train: 1.02467012405, norm: 0.260343700647\n",
      "Iteration 9250, loss_train: 0.913023352623, norm: 0.249013572931\n",
      "Iteration 9500, loss_train: 0.988859474659, norm: 0.258803904057\n",
      "Iteration 9750, loss_train: 0.901484787464, norm: 0.227098077536\n",
      "Iteration 10000, loss_train: 1.02666604519, norm: 0.287487834692\n",
      "Iteration 10250, loss_train: 0.995577931404, norm: 0.244314625859\n",
      "Iteration 10500, loss_train: 0.909880101681, norm: 0.24619436264\n",
      "Iteration 10750, loss_train: 0.980535268784, norm: 0.301822990179\n",
      "Iteration 11000, loss_train: 0.978165447712, norm: 0.247975513339\n",
      "Iteration 11250, loss_train: 0.983674108982, norm: 0.254238456488\n",
      "Iteration 11500, loss_train: 0.852584004402, norm: 0.247054114938\n",
      "Iteration 11750, loss_train: 0.989357113838, norm: 0.25311088562\n",
      "Iteration 12000, loss_train: 1.0722540617, norm: 0.278967142105\n",
      "Iteration 12250, loss_train: 1.00209259987, norm: 0.269548565149\n",
      "Iteration 12500, loss_train: 0.968022465706, norm: 0.279643714428\n",
      "Iteration 12750, loss_train: 0.904886007309, norm: 0.23350033164\n",
      "Iteration 13000, loss_train: 0.948264479637, norm: 0.256119072437\n",
      "Iteration 13250, loss_train: 0.894326686859, norm: 0.241066336632\n",
      "Iteration 13500, loss_train: 0.980372071266, norm: 0.252825349569\n",
      "Iteration 13750, loss_train: 0.915562689304, norm: 0.266113162041\n",
      "Iteration 14000, loss_train: 0.931724309921, norm: 0.257542699575\n",
      "Iteration 14250, loss_train: 0.902666807175, norm: 0.27886864543\n",
      "Iteration 14500, loss_train: 0.927887201309, norm: 0.238852456212\n",
      "Iteration 14750, loss_train: 0.99621874094, norm: 0.272991836071\n",
      "Iteration 15000, loss_train: 0.919795691967, norm: 0.237917304039\n",
      "Iteration 15250, loss_train: 0.950998723507, norm: 0.245809555054\n",
      "Iteration 15500, loss_train: 0.994830369949, norm: 0.273043781519\n",
      "Iteration 15750, loss_train: 0.899829566479, norm: 0.252308756113\n",
      "Iteration 16000, loss_train: 0.885306417942, norm: 0.233469799161\n",
      "Iteration 16250, loss_train: 0.919508993626, norm: 0.238274469972\n",
      "Iteration 16500, loss_train: 0.886282324791, norm: 0.249453365803\n",
      "Iteration 16750, loss_train: 0.903831243515, norm: 0.249828189611\n",
      "Iteration 17000, loss_train: 0.967866122723, norm: 0.253886431456\n",
      "Iteration 17250, loss_train: 0.911391198635, norm: 0.26304680109\n",
      "Iteration 17500, loss_train: 0.973458886147, norm: 0.262555956841\n",
      "Iteration 17750, loss_train: 0.910778701305, norm: 0.252756863832\n",
      "Iteration 18000, loss_train: 1.01824581623, norm: 0.267612546682\n",
      "Iteration 18250, loss_train: 0.868850886822, norm: 0.249156087637\n",
      "Iteration 18500, loss_train: 0.865971803665, norm: 0.247251495719\n",
      "Iteration 18750, loss_train: 0.977753520012, norm: 0.261595219374\n",
      "Iteration 19000, loss_train: 0.839849591255, norm: 0.234223678708\n",
      "Iteration 19250, loss_train: 0.972750365734, norm: 0.249874770641\n",
      "Iteration 19500, loss_train: 0.877806842327, norm: 0.246460944414\n",
      "Iteration 19750, loss_train: 0.866234064102, norm: 0.236672237515\n"
     ]
    }
   ],
   "source": [
    "hid = np.zeros((BATCH_SIZE, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "hid2 = np.zeros((BATCH_SIZE, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "\n",
    "train_batch_gen = data_batch_generator(train_corpus)\n",
    "\n",
    "for iteration in range(20000):\n",
    "    x, y = prep_batch_for_network(next(train_batch_gen))\n",
    "    loss_train, norm, hid, hid2 = f_train(x, y, hid, hid2)\n",
    "    \n",
    "    if iteration % 250 == 0:\n",
    "        print('Iteration {}, loss_train: {}, norm: {}'.format(iteration, loss_train, norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_values = lasagne.layers.get_all_param_values(l_out)\n",
    "d = {'param values': param_values,\n",
    "     'VOCABULARY': VOCABULARY, \n",
    "     'CHAR_TO_IX': CHAR_TO_IX,\n",
    "     'IX_TO_CHAR': IX_TO_CHAR,\n",
    "    }\n",
    "pickle.dump(d, open('gru_2layer_trained.pkl','w'), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pickle.load(open('lstm_trained.pkl', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasagne.layers.set_all_param_values(l_out, d['param values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss_train: 1.14895617962, norm: 0.31606566906\n",
      "Iteration 250, loss_train: 0.866210460663, norm: 0.241797029972\n",
      "Iteration 500, loss_train: 0.915615439415, norm: 0.24722892046\n",
      "Iteration 750, loss_train: 0.904083192348, norm: 0.244569957256\n",
      "Iteration 1000, loss_train: 0.920575082302, norm: 0.240894839168\n",
      "Iteration 1250, loss_train: 0.873084366322, norm: 0.215926349163\n",
      "Iteration 1500, loss_train: 0.942292571068, norm: 0.252579718828\n",
      "Iteration 1750, loss_train: 0.850891292095, norm: 0.222936615348\n",
      "Iteration 2000, loss_train: 0.932299792767, norm: 0.247698649764\n",
      "Iteration 2250, loss_train: 0.837965250015, norm: 0.21953189373\n",
      "Iteration 2500, loss_train: 0.86218047142, norm: 0.247443512082\n",
      "Iteration 2750, loss_train: 0.897492289543, norm: 0.243839144707\n",
      "Iteration 3000, loss_train: 0.859479665756, norm: 0.215487509966\n",
      "Iteration 3250, loss_train: 0.836775183678, norm: 0.224701076746\n",
      "Iteration 3500, loss_train: 0.861147880554, norm: 0.225737631321\n",
      "Iteration 3750, loss_train: 0.908664762974, norm: 0.235455602407\n",
      "Iteration 4000, loss_train: 0.897565841675, norm: 0.238181114197\n",
      "Iteration 4250, loss_train: 0.877911329269, norm: 0.216033935547\n",
      "Iteration 4500, loss_train: 0.741858363152, norm: 0.217439189553\n",
      "Iteration 4750, loss_train: 0.897414147854, norm: 0.233625903726\n",
      "Iteration 5000, loss_train: 0.842360556126, norm: 0.22497113049\n",
      "Iteration 5250, loss_train: 0.995061933994, norm: 0.256467610598\n",
      "Iteration 5500, loss_train: 0.815726578236, norm: 0.214364007115\n",
      "Iteration 5750, loss_train: 0.962676167488, norm: 0.245519533753\n",
      "Iteration 6000, loss_train: 0.844300091267, norm: 0.231136515737\n",
      "Iteration 6250, loss_train: 0.837576270103, norm: 0.225758820772\n",
      "Iteration 6500, loss_train: 0.953184306622, norm: 0.280467540026\n",
      "Iteration 6750, loss_train: 0.861745536327, norm: 0.24125996232\n",
      "Iteration 7000, loss_train: 0.942082345486, norm: 0.266616046429\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-f391cfdd34bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_batch_for_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batch_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mloss_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m250\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/eben/projects/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/eben/projects/Theano/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    942\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mallow_gc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 944\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    945\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m         \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode_input_storage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/eben/projects/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36mfree\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConstant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes_with_inner_function\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_sh.set_value(0.0002)\n",
    "\n",
    "hid = np.zeros((BATCH_SIZE, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "hid2 = np.zeros((BATCH_SIZE, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "\n",
    "train_batch_gen = data_batch_generator(train_corpus)\n",
    "\n",
    "for iteration in range(20000):\n",
    "    x, y = prep_batch_for_network(next(train_batch_gen))\n",
    "    loss_train, norm, hid, hid2 = f_train(x, y, hid, hid2)\n",
    "    \n",
    "    if iteration % 250 == 0:\n",
    "        print('Iteration {}, loss_train: {}, norm: {}'.format(iteration, loss_train, norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_fn = theano.function([x_sym, hid_init_sym, hid2_init_sym], [prob_out, hid_out, hid2_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hid = np.zeros((BATCH_SIZE, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "hid2 = np.zeros((BATCH_SIZE, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "startidx = None\n",
    "losses = []\n",
    "\n",
    "for iteration in range(50):\n",
    "    batch, startidx = get_data_batch(val_corpus, startidx=startidx)\n",
    "    x, y = prep_batch_for_network(batch)\n",
    "    loss_val, hid, hid2 = f_val(x, y, hid, hid2)\n",
    "    \n",
    "    losses.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0524255"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence = ''\n",
    "\n",
    "x0 = np.zeros((1, SEQUENCE_LENGTH, VOCAB_SIZE), dtype='float32')\n",
    "#hid0 = np.zeros((1, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "hid0 = np.copy(hid)[:1]\n",
    "for _ in range(500):\n",
    "    p, _ = predict_fn(x0, hid0)\n",
    "    p = p[0, -1]\n",
    "    p = p/(p.sum() + 1e-6)\n",
    "    s = np.random.multinomial(1, p)\n",
    "    sentence += IX_TO_CHAR[s.argmax(-1)]\n",
    "    x0[:,:-1] = x0[:,1:]\n",
    "    x0[:,-1,:] = s\n",
    "    if sentence[-1] == '\\n':\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mpanilic assembly is an oxide state; amine cramped to generate units comprising a wex carbarr. \\n'"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence = 'A claim'\n",
    "\n",
    "primer = np.array([CHAR_TO_ONEHOT[c] for c in sentence])\n",
    "\n",
    "x0 = np.zeros((1, SEQUENCE_LENGTH, VOCAB_SIZE), dtype='float32')\n",
    "x0[:, -7:] = primer\n",
    "for _ in range(500):\n",
    "    p, _ = predict_fn(x0, hid0)\n",
    "    p = p[0, -1]\n",
    "    p = p/(p.sum() + 1e-6)\n",
    "    s = np.random.multinomial(1, p)\n",
    "    sentence += IX_TO_CHAR[s.argmax(-1)]\n",
    "    x0[:,:-1] = x0[:,1:]\n",
    "    x0[:,-1,:] = s\n",
    "    if sentence[-1] == '\\n':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A claima', wherein the resentical wolk vatues on the interument instruction of said stalle diachssester into a varvable metal froquee in surface and the bond and their each orkering pradered. \\n\""
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_input = lasagne.layers.InputLayer((None, 1, VOCAB_SIZE))\n",
    "\n",
    "l_rnn = lasagne.layers.GRULayer(l_input,\n",
    "                                  num_units=RNN_HIDDEN_SIZE,\n",
    "                                  grad_clipping=5.,\n",
    "                                  hid_init=hid_init_sym,\n",
    "                                  )\n",
    "\n",
    "l_rnn2 = lasagne.layers.GRULayer(l_rnn,\n",
    "                                  num_units=RNN_HIDDEN_SIZE,\n",
    "                                  grad_clipping=5.,\n",
    "                                  hid_init=hid2_init_sym,\n",
    "                                  )\n",
    "\n",
    "\n",
    "l_shp = lasagne.layers.ReshapeLayer(l_rnn2, (-1, RNN_HIDDEN_SIZE))\n",
    "\n",
    "l_decoder = lasagne.layers.DenseLayer(l_shp,\n",
    "                                      num_units=VOCAB_SIZE,\n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "l_out = lasagne.layers.ReshapeLayer(l_decoder, (-1, 1, VOCAB_SIZE))\n",
    "\n",
    "hid_out, hid2_out, prob_out = lasagne.layers.get_output([l_rnn, l_rnn2, l_out], {\n",
    "                        l_input: x_sym,\n",
    "                    })\n",
    "hid_out = hid_out[:, -1]\n",
    "hid2_out = hid2_out[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasagne.layers.set_all_param_values(l_out, d['param values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_fn = theano.function([x_sym, hid_init_sym, hid2_init_sym], [prob_out, hid_out, hid2_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence = ''\n",
    "hid = np.zeros((1, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "hid2 = np.zeros((1, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "x = np.zeros((1, 1, VOCAB_SIZE), dtype='float32')\n",
    "primer = 'An apparatus according to claim 1, characterized in that\\n'\n",
    "#primer = '\\n' * SEQUENCE_LENGTH\n",
    "primer = ''\n",
    "#primer = 'n-hydroxy'\n",
    "#primer = 'octane'\n",
    "x[:, :, :] = 1./VOCAB_SIZE\n",
    "\n",
    "for c in primer:\n",
    "    x[0, 0, :] = CHAR_TO_ONEHOT[c]\n",
    "    p, hid, hid2 = predict_fn(x, hid, hid2)\n",
    "    \n",
    "for _ in range(500):\n",
    "    p, hid, hid2 = predict_fn(x, hid, hid2)\n",
    "    p = p[0, 0]\n",
    "    p = p/(p.sum() + 1e-6)\n",
    "    s = np.random.multinomial(1, p)\n",
    "    sentence += IX_TO_CHAR[s.argmax(-1)]\n",
    "    x[0, 0, :] = s\n",
    "    if sentence[-1] == '\\n':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 substituting the natural light eesition using the signal is smaller than, on the end of the block display. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "primers = val_corpus.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIMER: The intelligent imaging system of any of the preceding claims, further characterized in that said personality module (2114) is connected to said at least one print head, and wherein said personality module (2114) is connected to sense movement of said moving web and synchronizes the output of raster data from said staging memory to said at least one print head with movement of said web (72). \n",
      "\n",
      "GENERATED: A printhead capture according to any one of the preceding claims, characterized in that said incliner cabin (124) is outside the mold area c) that prevent that the hole pin is no more preventing second resistance of the tne form and with \"(A). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = ''\n",
    "hid = np.zeros((1, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "hid2 = np.zeros((1, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "x = np.zeros((1, 1, VOCAB_SIZE), dtype='float32')\n",
    "\n",
    "primer = np.random.choice(primers) + '\\n'\n",
    "\n",
    "for c in primer:\n",
    "    p, hid, hid2 = predict_fn(x, hid, hid2)\n",
    "    x[0, 0, :] = CHAR_TO_ONEHOT[c]\n",
    "    \n",
    "for _ in range(500):\n",
    "    p, hid, hid2 = predict_fn(x, hid, hid2)\n",
    "    p = p[0, 0]\n",
    "    p = p/(p.sum() + 1e-6)\n",
    "    s = np.random.multinomial(1, p)\n",
    "    sentence += IX_TO_CHAR[s.argmax(-1)]\n",
    "    x[0, 0, :] = s\n",
    "    if sentence[-1] == '\\n':\n",
    "        break\n",
    "        \n",
    "print('PRIMER: ' + primer)\n",
    "print('GENERATED: ' + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
